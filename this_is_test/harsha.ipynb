{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import requests\n",
    "\n",
    "data = requests.get(\"https://locations.riteaid.com/\").text\n",
    "soup = BeautifulSoup(data, \"lxml\")\n",
    "links = set()\n",
    "stores_list = list()\n",
    "store_name = list()\n",
    "addresses = list()\n",
    "states = list()\n",
    "file1 = open(\"RiteAID.txt\", \"w\")\n",
    "\n",
    "for e in soup.findAll('div', {\"class\": \"c-directory-list-content-wrapper\"}):\n",
    "    store = e.text.strip('\\n \\t')\n",
    "    store_name.append(store.encode('ascii', 'ignore'))\n",
    "\n",
    "# print \"Store count:\",len(store_name)\n",
    "\n",
    "stores = list()\n",
    "AllData = list()\n",
    "d = dict()\n",
    "for x in soup.findAll(\"ul\", {\"class\": \"c-directory-list-content\"}):\n",
    "    for i in x:\n",
    "        str2 = str(i).split(\">\")\n",
    "        str3 = str2[2].split(\"<\")\n",
    "        # print str3[0]\n",
    "        states.append(str3[0])\n",
    "        # Innner state names\n",
    "        str4 = str(i).split(\"href=\\\"\")\n",
    "        str5 = str4[1].split(\"\\\">\")\n",
    "        d = dict\n",
    "        # print(str5[0])\n",
    "        # for foo in soup.find_all('div', attrs={'class': 'foo'}):\n",
    "        # \tbar = foo.find('div', attrs={'class': 'bar'})\n",
    "        # \tprint(bar.text)\n",
    "        data1 = requests.get(\"https://locations.riteaid.com/\" + str5[0]).text\n",
    "        soup1 = BeautifulSoup(data1, 'lxml')\n",
    "        for x1 in soup1.findAll(\"ul\", {\"class\": \"c-directory-list-content\"}):\n",
    "            for i1 in x1:\n",
    "                # print i1\n",
    "                str6 = str(i1).split(\"..\")\n",
    "                str7 = str6[1].split(\"\\\">\")\n",
    "                # print(str7[0])\n",
    "                data2 = requests.get(\"https://locations.riteaid.com\" + str7[0]).text\n",
    "                soup2 = BeautifulSoup(data2, 'lxml')\n",
    "                for foo in soup2.find_all('div', {'class': 'Nap-left'}):\n",
    "                    for x2 in foo.findAll(\"span\", {\"class\": \"c-address-street\"}):\n",
    "                        for i2 in x2:\n",
    "                            str8 = str(i2).split(\">\")\n",
    "                            str9 = str8[1].split(\"<\")\n",
    "                            file1.write(str(str9[0]) + \",\")\n",
    "                    for x3 in foo.findAll(\"span\", {\"class\": \"c-address-postal-code\"}):\n",
    "                        for i3 in x3:\n",
    "                            file1.write(str(i3) + \",\")\n",
    "                    for x4 in foo.findAll(\"span\", {\"class\": \"c-address-city\"}):\n",
    "                        for i4 in x4:\n",
    "                            # print(i4)\n",
    "                            str10 = str(i4).split(\">\")\n",
    "                            if str10[1].startswith(\",\"):\n",
    "                                continue\n",
    "                            else:\n",
    "                                str11 = str10[1].split(\"<\")\n",
    "                                file1.write(str(str11[0]) + \",\")\n",
    "                    for x5 in foo.findAll(\"abbr\", {\"class\": \"c-address-state\"}):\n",
    "                        for i5 in x5:\n",
    "                            file1.write(str(i5) + \",\")\n",
    "                    for x6 in foo.findAll(\"span\", {\"class\": \"c-phone-number-span c-phone-main-number-span\"}):\n",
    "                        for i6 in x6:\n",
    "                            file1.write(str(i6) + \",\")\n",
    "                    for x7 in foo.findAll(\"span\", {\"class\": \"coordinates\"}):\n",
    "                        for i7 in x7:\n",
    "                            str12 = str(i7).split(\"content=\")\n",
    "                            str13 = str12[1].split(\"itemprop=\")\n",
    "                            if str13[1].__contains__(\"latitude\"):\n",
    "                                file1.write(str(str13[0]) + \",\")\n",
    "                            else:\n",
    "                                file1.write(str(str13[0]))\n",
    "                    file1.write(\"\\n\")\n",
    "                for foo in soup2.find_all('div', {'class': 'location-list-wrap'}):\n",
    "                    for x2 in foo.findAll(\"span\", {\"class\": \"c-address-street\"}):\n",
    "                        for i2 in x2:\n",
    "                            str8 = str(i2).split(\">\")\n",
    "                            str9 = str8[1].split(\"<\")\n",
    "                            file1.write(str(str9[0]) + \",\")\n",
    "                    for x3 in foo.findAll(\"span\", {\"class\": \"c-address-postal-code\"}):\n",
    "                        for i3 in x3:\n",
    "                            file1.write(str(i3) + \",\")\n",
    "                    for x4 in foo.findAll(\"span\", {\"class\": \"c-address-city\"}):\n",
    "                        for i4 in x4:\n",
    "                            # print(i4)\n",
    "                            str10 = str(i4).split(\">\")\n",
    "                            if str10[1].startswith(\",\"):\n",
    "                                continue\n",
    "                            else:\n",
    "                                str11 = str10[1].split(\"<\")\n",
    "                                file1.write(str(str11[0]) + \",\")\n",
    "                    for x5 in foo.findAll(\"abbr\", {\"class\": \"c-address-state\"}):\n",
    "                        for i5 in x5:\n",
    "                            file1.write(str(i5) + \",\")\n",
    "                    for x6 in foo.findAll(\"span\", {\"class\": \"c-phone-number-span c-phone-main-number-span\"}):\n",
    "                        for i6 in x6:\n",
    "                            file1.write(str(i6) + \",\")\n",
    "                    for x7 in foo.findAll(\"span\", {\"class\": \"coordinates\"}):\n",
    "                        for i7 in x7:\n",
    "                            str12 = str(i7).split(\"content=\")\n",
    "                            str13 = str12[1].split(\"itemprop=\")\n",
    "                            if str13[1].__contains__(\"latitude\"):\n",
    "                                latitude = str13[0]\n",
    "                                file1.write(str(str13[0]) + \",\")\n",
    "                            else:\n",
    "                                file1.write(str(str13[0]))\n",
    "                    file1.write(\"\\n\")\n",
    "file1.close()\n",
    "\n",
    "# for e in soup.findAll('div', {\"class\": \"c-directory-list-content-wrapper\"}):\n",
    "# store = e.text.strip('\\n \\t')\n",
    "# store_name.append(store.encode('ascii', 'ignore'))\n",
    "# if isinstance(i, Tag)\n",
    "#     str1 = i.get(\"onclick\")\n",
    "#     if str1.startswith(\"RWD.store.util.store_page_direction('http://\"):\n",
    "#         str2 = str1.split(\"RWD.store.util.store_page_direction('http://maps.google.com/maps?\")\n",
    "#             else:\n",
    "#                 str2 = str1.split(\"RWD.store.util.store_page_direction('https://www.google.com/maps/place/\")\n",
    "#             str3 = str2[1].split(\"'\")\n",
    "#             str4 = str3[0]\n",
    "#             str5 = str4.split(\"&\")\n",
    "#\n",
    "#          for str6 in str5:\n",
    "#                 if 'sll=' in str6 or 'll=' in str6:\n",
    "#                     result = re.search('ll=(.*)', str6)\n",
    "#                     sll.append((result.group(1).split(',')))\n",
    "#                     break\n",
    "#                 elif \"/@\" in str6:\n",
    "#                     result = re.search('@(.*)z/', str6)\n",
    "#                     coordinates = result.group(1).split(',')[0:2]\n",
    "#                     sll.append(coordinates)\n",
    "#             stores.append(str5)\n",
    "#\n",
    "# print \"SLL count:\", len(sll)\n",
    "# print \"Store count:\", len(stores)\n",
    "# #\n",
    "# #\n",
    "# for e in soup.findAll(\"p\", {\"class\": \"localStoreAddressBar\"}):\n",
    "#     address = []\n",
    "#     for x in e.text.replace('\\n', '').split('\\n'):\n",
    "#         for y in x.strip('\\t').split('\\t'):\n",
    "#             if y != '':\n",
    "#                 address.append(y.encode('ascii', 'ignore'))\n",
    "#     addresses.append(address)\n",
    "#\n",
    "# final_address_list = list()\n",
    "#\n",
    "# for store, address , ll in zip(store_name, addresses, sll):\n",
    "#     final_address_list.append([store] + address + ll)\n",
    "#\n",
    "# print final_address_list\n",
    "#\n",
    "# print len(final_address_list)\n",
    "#\n",
    "# for store in final_address_list:\n",
    "#     if len(store) == 7:\n",
    "#         print store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
